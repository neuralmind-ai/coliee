{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLIEE2021_Task1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDuueuY0iQ2I"
      },
      "source": [
        "!pip install pyserini==0.10.1.0 --quiet  \n",
        "!pip install jsonlines\n",
        "\n",
        "!unzip /content/task1_files.zip -d /content/Coliee_2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0guc1c0iZ_z"
      },
      "source": [
        "from pyserini.search import SimpleSearcher\n",
        "import jsonlines\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import json\n",
        "import spacy\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report)\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "test_labels = json.load(open('/content/task1_test_labels_2021.json', 'r'))\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
        "\n",
        "def example2seg(docs, max_length, stride):\n",
        "    \"\"\"\n",
        "    Receives a document and segment it\n",
        "\n",
        "    Args:\n",
        "      docs: Document\n",
        "      max_length: number of sentences in each segment\n",
        "      stride: stride\n",
        "    Returns:\n",
        "      One segmented document.\n",
        "    \"\"\"\n",
        "    doc = nlp(docs) \n",
        "    \n",
        "    sentences = [sent.string.strip() for sent in doc.sents]\n",
        "\n",
        "    segments = []\n",
        "    for i in range(0, len(sentences), stride):\n",
        "        segment = ' '.join(sentences[i:i + max_length])\n",
        "        segments.append(segment)\n",
        "        if i + max_length >= len(sentences):\n",
        "            break\n",
        "\n",
        "    return segments\n",
        "\n",
        "def get_base_case (path):\n",
        "    \"\"\"\n",
        "    Read one base case and segment it\n",
        "\n",
        "    Args:\n",
        "      path: Path to file\n",
        "\n",
        "    Returns:\n",
        "      One segmented base case.\n",
        "    \"\"\"\n",
        "    path_to_file = '/content/Coliee_2021/{}'.format(path) \n",
        "    with open(path_to_file) as f:\n",
        "        contents = f.read()\n",
        "        f.close()\n",
        "   \n",
        "    contents = contents.replace('\\n','').replace('FRAGMENT_SUPPRESSED','')\n",
        "    base_case = ' '.join(contents.split())\n",
        "\n",
        "    segmented_base_case = example2seg(base_case, 10, 5) \n",
        "    return segmented_base_case[0:25]\n",
        "\n",
        "def index_doc(path, save=False, french=False): \n",
        "    \"\"\"\n",
        "    Read one candidate case and segment it. It also saves the candidate case as json to use in Pyserini.\n",
        "\n",
        "    Args:\n",
        "      path: Path to candidate file (string)    \n",
        "      save: Save as json (bool)\n",
        "      french: Use French (bool)\n",
        "    Returns:\n",
        "      One segmented candidate case.\n",
        "    \"\"\"\n",
        "    \n",
        "    path_to_file = '/content/Coliee_2021/{}'.format(path) \n",
        "    with open(path_to_file) as f:\n",
        "        contents = f.read()\n",
        "        f.close() \n",
        "    \n",
        "    contents = contents.replace('\\n','').replace('FRAGMENT_SUPPRESSED','')\n",
        "    if len(contents.split()) <= 10:\n",
        "        contents = contents.replace('<p style=','This is a wrong document. It should have only one segment. Thats it.').replace('FRAGMENT_SUPPRESSED','')\n",
        "        contents = 'This is a wrong document. It should have only one segment. Thats it.'\n",
        "    \n",
        "    candidate_case = ' '.join(contents.split()) \n",
        "    segments_candidate = example2seg(candidate_case, 10, 5)\n",
        "    \n",
        "    list_segments_candidate = []\n",
        "    for cont, segs in enumerate (segments_candidate):\n",
        "        dict_ = { \"id\": \"{}_segment{}-2021\".format(path,str(cont+1)), \"contents\": segs}\n",
        "        list_segments_candidate.append(dict_)   \n",
        "        \n",
        "        if save == True:\n",
        "            with jsonlines.open('/content/tmp_candidates/candidate.jsonl', mode='a') as writer:\n",
        "                writer.write(dict_)\n",
        "\n",
        "def get_correct(top_sorted_list_dict, example):\n",
        "    \"\"\"\n",
        "    Remove candidate cases that don't belong to an specific base case\n",
        "\n",
        "    Args:\n",
        "      sorted_list_dict_candidate: List of dicts containing the BM25's searcher answers\n",
        "      example: base case number to be removed\n",
        "    Returns:\n",
        "      The correct segments for each base case.\n",
        "    \"\"\"\n",
        "    correct_top_sorted_list_dict = []\n",
        "    for dicts in top_sorted_list_dict:\n",
        "        if dicts['candidate'].endswith('2021'): \n",
        "            if dicts['candidate'].split('.txt')[0] != example:\n",
        "                correct_top_sorted_list_dict.append(dicts)\n",
        "\n",
        "    return correct_top_sorted_list_dict\n",
        "\n",
        "def fix_names(top_sorted_list_dict):\n",
        "    \"\"\"\n",
        "    Fix dict name to perform evaluation\n",
        "\n",
        "    Args:\n",
        "     top_sorted_list_dict: BM25's answers\n",
        "\n",
        "    Returns:\n",
        "      list of dicts\n",
        "    \"\"\"  \n",
        "    for dicts in top_sorted_list_dict:\n",
        "        dicts['candidate'] = dicts['candidate'].split('.txt')[0]\n",
        "\n",
        "    return top_sorted_list_dict\n",
        "\n",
        "def get_top_scores(sorted_list_dict_candidate):\n",
        "    \"\"\"\n",
        "    Get the best segments score for each candidate\n",
        "\n",
        "    Args:\n",
        "      sorted_list_dict_candidate: List of dicts containing the BM25's searcher answers\n",
        "\n",
        "    Returns:\n",
        "      The best segment for each candidate case.\n",
        "    \"\"\"\n",
        "    top_sorted = []\n",
        "    for sorted_candidates in sorted_list_dict_candidate:\n",
        "        if sorted_candidates['candidate'] in [top['candidate'] for top in top_sorted]:\n",
        "            pass\n",
        "        else:\n",
        "            top_sorted.append(sorted_candidates)\n",
        "    return top_sorted\n",
        "\n",
        "  \n",
        "def sum_scores(list_dict):\n",
        "    \"\"\"\n",
        "    Get the sum of segments score for each candidate\n",
        "\n",
        "    Args:\n",
        "      list_dict_candidate: List of dicts containing the BM25's searcher answers\n",
        "\n",
        "    Returns:\n",
        "      The sum of scores for each candidate case.\n",
        "    \"\"\"\n",
        "    computed = []\n",
        "    for iterate in list_dict:\n",
        "        soma = sum(item['score'] for item in list_dict if item['candidate'] == iterate['candidate'] )\n",
        "        new_dict = {'candidate':iterate['candidate'], 'score':soma}\n",
        "        if new_dict not in computed:\n",
        "            computed.append(new_dict)\n",
        "\n",
        "    return computed\n",
        "\n",
        "def evaluate_one_base_case(n_case, parameter_K, number_segs):\n",
        "    \"\"\"\n",
        "    Receives a list of segments and evaluate one base case on BM25\n",
        "\n",
        "    Args:\n",
        "      n_case: Base case path\n",
        "      number_segs: number of input segments per document (int)\n",
        "      parameter_K: number of retrieved segments per input segment\n",
        "\n",
        "    Returns:\n",
        "      The best segment for each candidate case.\n",
        "    \"\"\"  \n",
        "    list_hits = []\n",
        "    list_dict_candidate = []\n",
        " \n",
        "    base_case = get_base_case(n_case) \n",
        "\n",
        "    for bases in base_case[0:number_segs]:\n",
        "        hits = searcher.search(bases[0:1024], k=parameter_K)\n",
        "        list_hits = list_hits + hits\n",
        "\n",
        "    for num in range(len(list_hits)):\n",
        "        dict_candidate = {'candidate':list_hits[num].docid, 'score': list_hits[num].score}\n",
        "        list_dict_candidate.append(dict_candidate)\n",
        "           \n",
        "    sorted_list_dict_candidate = sorted(list_dict_candidate, key=lambda k : k['score'], reverse=True)\n",
        "\n",
        "    correct_list_dict = get_correct(sorted_list_dict_candidate, n_case.split('.txt')[0])\n",
        "    correct_list_dict = fix_names(correct_list_dict)\n",
        "    top_sorted = get_top_scores(correct_list_dict)\n",
        "    sum_dict_ = sum_scores(correct_list_dict)\n",
        "    sum_dict_list = sorted(sum_dict_, key=lambda k : k['score'], reverse=True)\n",
        "   \n",
        "    return top_sorted, sum_dict_list\n",
        "\n",
        "def run_bm25 (list_paths, number_segs, save = False, parameter_K = 1000):\n",
        "    \"\"\"\n",
        "    Run BM25\n",
        "\n",
        "    Args:\n",
        "      list_paths: list of paths to run bm25\n",
        "      number_segs: number of input segments per document (int)\n",
        "      parameter_K: number of retrieved segments per input segment\n",
        "\n",
        "    Returns:\n",
        "      List of dict containing BM25 answers. dict = {candidate: <candidate>, score: <score>}\n",
        "    \"\"\"  \n",
        "    list_score_top = []\n",
        "    list_score_sum = []\n",
        "    cont = 0\n",
        "    for casos_base in tqdm(list_paths):  \n",
        "        \n",
        "        top_sorted_list_dict, sum_list_dict = evaluate_one_base_case(casos_base, parameter_K, number_segs)\n",
        "        list_score_top.append(top_sorted_list_dict)\n",
        "        list_score_sum.append(sum_list_dict)\n",
        "     \n",
        "        \n",
        "    return list_score_top, list_score_sum\n",
        "\n",
        "\n",
        "def get_top_n(list_score_all, n):\n",
        "    \"\"\"\n",
        "    Get top n candidates\n",
        "\n",
        "    Args:\n",
        "      list_score_all: BM25's answers\n",
        "      n: number of top candidates to be chosen\n",
        "\n",
        "    Returns:\n",
        "      list of dicts containing top n\n",
        "    \"\"\"  \n",
        "    new_list_score_all = []\n",
        "    for tentativa in list_score_all:\n",
        "        teste = sorted(tentativa, key=lambda k : k['score'], reverse=True)[:n]\n",
        "        new_list_score_all.append(teste)\n",
        "    \n",
        "    return new_list_score_all\n",
        "\n",
        "def my_classification_report(list_label_ohe, list_answer_ohe):\n",
        "    \"\"\"\n",
        "    Calculate F1, Precision and Recall\n",
        "\n",
        "    Args:\n",
        "      list_label_ohe: list of one hot encodings of the labels\n",
        "      list_answer_ohe: list of one hot encodings of the answers\n",
        "\n",
        "    Returns:\n",
        "      F1, Precision, Recall\n",
        "    \"\"\"  \n",
        "    true_positive = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "\n",
        "    for list_label, list_ohe in zip(list_label_ohe, list_answer_ohe):\n",
        "      \n",
        "        for l, o in zip(list_label, list_ohe):\n",
        "          \n",
        "            if o == 1 and l == 1:\n",
        "                true_positive += 1\n",
        "            elif o == 0 and l == 1:\n",
        "                false_negative += 1\n",
        "            elif o == 1 and l == 0:\n",
        "                false_positive += 1\n",
        "\n",
        "     \n",
        "\n",
        "    precision = true_positive/(true_positive+false_positive)\n",
        "    recall = true_positive/(true_positive+false_negative)\n",
        "    f1 = 2*((precision*recall)/(precision + recall))\n",
        "\n",
        "    return f1, precision, recall\n",
        "\n",
        "def id_to_ohe(lista):\n",
        "    \"\"\"\n",
        "    Convert list of numbers in one hot encoding\n",
        "\n",
        "    Args:\n",
        "      lista: list of integers\n",
        "      \n",
        "\n",
        "    Returns:\n",
        "      List of one hot encodings\n",
        "    \"\"\"  \n",
        "    list_ref = list(range(1, 100000)) # 201\n",
        "    new_list_ref = []\n",
        "    for t in list_ref:\n",
        "        if t in lista:\n",
        "            new_list_ref.append(1)\n",
        "        else:\n",
        "            new_list_ref.append(0)\n",
        "\n",
        "    return new_list_ref\n",
        "\n",
        "def evaluate(list_answers, label):\n",
        "    \"\"\"\n",
        "    Convert both list of numbers in one hot encoding\n",
        "\n",
        "    Args:\n",
        "      list_answers: list of answers\n",
        "      label: list of labels\n",
        "      \n",
        "\n",
        "    Returns:\n",
        "      Lists of one hot encodings\n",
        "    \"\"\"  \n",
        "    answer_ohe = id_to_ohe([int(l.split('.txt')[0]) for l in list_answers])\n",
        "    label_ohe = id_to_ohe([int(k.split('.txt')[0]) for k in label]) #521 a 650\n",
        "    \n",
        "    return answer_ohe, label_ohe\n",
        "\n",
        "def get_list_answers(list_score):\n",
        "    \"\"\"\n",
        "    Get answer from dicts\n",
        "\n",
        "    Args:\n",
        "      list_score: \n",
        "      \n",
        "    Returns:\n",
        "      Lists of answers\n",
        "    \"\"\"  \n",
        "    teste = [d['candidate'] for d in list_score]\n",
        "    return teste\n",
        "\n",
        "def get_max_percentage(list_score_all, percent):\n",
        "    \"\"\"\n",
        "    Select answers above threeshold. If score_candidate > max(score_candidate)*percent -> select candidate\n",
        "\n",
        "    Args:\n",
        "      list_score_all: BM25's answers\n",
        "      percent: Threshold\n",
        "\n",
        "    Returns:\n",
        "      List of selected dicts\n",
        "    \"\"\"  \n",
        "    list_dict_percent = []\n",
        "    for sample in list_score_all:\n",
        "        try:\n",
        "            maximum = max(sample, key=lambda x:x['score'])  \n",
        "        except:\n",
        "            if len(sample) == 0:\n",
        "                pass\n",
        "            else:\n",
        "                maximum = sample[0]      \n",
        "        dict_percent = [dicts for dicts in sample if dicts['score'] > maximum['score']*percent]     \n",
        "        list_dict_percent.append(dict_percent)\n",
        "        \n",
        "    return list_dict_percent\n",
        "\n",
        "def apply_threshold(list_score_all, threshold):\n",
        "    \"\"\"\n",
        "    Select answers above threeshold. If score_candidate > threshold -> select candidate\n",
        "\n",
        "    Args:\n",
        "      list_score_all: BM25's answers\n",
        "      threshold: Threshold\n",
        "\n",
        "    Returns:\n",
        "      List of selected dicts\n",
        "    \"\"\"  \n",
        "    list_dict_threshold = []\n",
        "    for samples in list_score_all:\n",
        "        dict_threshold = [dicts for dicts in samples if dicts['score'] > threshold]\n",
        "        list_dict_threshold.append(dict_threshold)\n",
        "\n",
        "    return list_dict_threshold\n",
        "\n",
        "def grid(threshold, top_n, percentss, list_dict):\n",
        "    \"\"\"\n",
        "    Test three different heuristics parameters\n",
        "\n",
        "    Args:\n",
        "      threshold: Select score above this threshold \n",
        "      list_dict: BM25's answers\n",
        "      top_n: Select top N scores \n",
        "      percentss: Select score above max(candidate_score)#percentss\n",
        "      \n",
        "    Returns:\n",
        "      F1, Precision, Recall\n",
        "    \"\"\"  \n",
        "    list_dict_percent = get_max_percentage(list_dict, percentss) \n",
        "    list_dict_threshold = apply_threshold(list_dict_percent, threshold) # try threshold\n",
        "    new_list_score_all = get_top_n(list_dict_threshold, top_n) # try top_n    \n",
        "    list_answer_ohe = []\n",
        "    list_label_ohe = []\n",
        "\n",
        "    for nn in range(len(new_list_score_all)):\n",
        "        teste =  get_list_answers(new_list_score_all[nn])\n",
        "        answer_ohe, label_ohe = evaluate(teste, list(test_labels.values())[nn])        \n",
        "        list_answer_ohe.append(answer_ohe)\n",
        "        list_label_ohe.append(label_ohe)\n",
        "\n",
        "    val_micro_f1_score = f1_score(list_label_ohe, list_answer_ohe, average='micro')\n",
        "    f1, precision, recall = my_classification_report(list_label_ohe, list_answer_ohe)\n",
        "\n",
        "    return f1, precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrxjHngMmZoy"
      },
      "source": [
        "## Main code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWAUam3rjSdW"
      },
      "source": [
        "def index_all():\n",
        "    '''\n",
        "    Create documents in json format to be indexed before apply bm25\n",
        "    '''\n",
        "    !rm -r /content/candidates\n",
        "    !rm -r /content/tmp_candidates\n",
        "    !mkdir /content/tmp_candidates\n",
        "    mypath = '/content/Coliee_2021'\n",
        "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))] # get paths\n",
        "    i = 0\n",
        "    for path_candidate in tqdm(onlyfiles):\n",
        "        index_doc(path_candidate, True)\n",
        "    \n",
        "        i+=1\n",
        "    \n",
        "index_all()\n",
        "\n",
        "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator \\\n",
        "-threads 1 -input /content/tmp_candidates \\\n",
        "-index /content/candidates/indexes -storePositions -storeDocvectors -storeRaw\n",
        "\n",
        "searcher = SimpleSearcher('/content/candidates/indexes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItBfoCIJmhQP"
      },
      "source": [
        "### Run BM25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SDezp2jbtk"
      },
      "source": [
        "# number of input segments per document\n",
        "number_segs = 15 # @param {type: \"integer\"}\n",
        "\n",
        "# number of retrieved segments per input segment\n",
        "parameter_K = 1000 # @param {type: \"integer\"}\n",
        "\n",
        "# Run BM25\n",
        "list_score_top, list_score_sum = run_bm25(test_labels, \n",
        "                                          number_segs, \n",
        "                                          True, \n",
        "                                          parameter_K) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF4P__xamjsj"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0ptrUblyyM"
      },
      "source": [
        "list_threshold = [10, 20, 40, 60, 80, 90, 95]\n",
        "list_top = [5, 10, 15, 20, 200]\n",
        "list_percent = [0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "list_tuples = []\n",
        "\n",
        "for thresholds in list_threshold:\n",
        "    for tops in list_top:\n",
        "        for percents in list_percent:\n",
        "            f1, precision, recall = grid(thresholds, tops, percents, list_score_top)           \n",
        "            tuples = (thresholds, tops, percents, f1, precision, recall)\n",
        "            list_tuples.append(tuples)\n",
        "         \n",
        "sorted_list = sorted(list_tuples, key=lambda x: x[3], reverse=True)\n",
        "print('Threshold, Top_N, Percent, F1, Precision, Recall')\n",
        "sorted_list[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}